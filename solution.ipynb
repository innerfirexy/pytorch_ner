{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import *\n",
    "from scripts.embedding_fabric import EmbeddingFabric\n",
    "from scripts.indexer import Indexer\n",
    "from scripts.metrics import *\n",
    "from scripts.model import *\n",
    "from scripts.training_model import *\n",
    "from scripts.visual_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/train.txt'\n",
    "DEV_PATH = 'data/dev.txt'\n",
    "TEST_PATH = 'data/test.txt'\n",
    "EMBEDDINGS_PATH = 'embeddings/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:03<00:00, 117832.89it/s]\n"
     ]
    }
   ],
   "source": [
    "glove = load_embedding_dict(EMBEDDINGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = read_ner_data_from_connl(TRAIN_PATH)\n",
    "val_words, val_tags = read_ner_data_from_connl(DEV_PATH)\n",
    "test_words, test_tags = read_ner_data_from_connl(TEST_PATH)\n",
    "\n",
    "data_dict = {\n",
    "    'train': (words, tags),\n",
    "    'dev': (val_words, val_tags),\n",
    "    'test': (test_words, test_tags)\n",
    "}\n",
    "\n",
    "words_indexer = Indexer(words)\n",
    "tags_indexer = Indexer(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNKNOWN>\n",
      "['<UNKNOWN>', 'B-ORG', 'O', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'I-MISC', 'I-LOC']\n"
     ]
    }
   ],
   "source": [
    "print(tags_indexer.index_to_element(0))\n",
    "print(tags_indexer.indices_to_elements([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 100\n",
    "\n",
    "models = {}\n",
    "for strat in ['b', 'c']: # original ['a', 'b', 'c']\n",
    "    strategy = f\"strategy_{strat}\"\n",
    "    model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM,\n",
    "                   tags_indexer.size(), \n",
    "                   lambda: EmbeddingFabric.get_embedding_layer(words_indexer, glove, strategy))\n",
    "    \n",
    "    models[strategy] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "labels = [x for x in tags_indexer.get_element_to_index_dict().values()]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_data = {}\n",
    "trained_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training strategy_b model\n",
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1591 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:27<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 48.10175979940079\n",
      "Precision - 0.6486940405510399\n",
      "Recall - 0.37005806110498374\n",
      "F1-score - 0.4973725761716654\n",
      "F0.5-score - 0.5297032602522971\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.7209014270928104\n",
      "Recall - 0.3962113927009723\n",
      "F1-score - 0.5495764382332381\n",
      "F0.5-score - 0.6098256065680436\n",
      "\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:27<00:00, 18.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 31.869849692433043\n",
      "Precision - 0.7279421680540632\n",
      "Recall - 0.5439108262600213\n",
      "F1-score - 0.5746032519562444\n",
      "F0.5-score - 0.6140414445680379\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.7597182235727741\n",
      "Recall - 0.5302891611345213\n",
      "F1-score - 0.5829270966298868\n",
      "F0.5-score - 0.6364290902187445\n",
      "\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:26<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 25.18623580990592\n",
      "Precision - 0.78532404936878\n",
      "Recall - 0.6519632782675134\n",
      "F1-score - 0.6948613947407765\n",
      "F0.5-score - 0.7370530500899704\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.7909236986886817\n",
      "Recall - 0.5918669970201372\n",
      "F1-score - 0.6525800116189573\n",
      "F0.5-score - 0.7111836228801584\n",
      "\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:29<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 21.86498760194111\n",
      "Precision - 0.8080631985278025\n",
      "Recall - 0.7044387595883508\n",
      "F1-score - 0.7435945386109684\n",
      "F0.5-score - 0.7772205141118378\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.80390495444187\n",
      "Recall - 0.6315036091737652\n",
      "F1-score - 0.6897865415615755\n",
      "F0.5-score - 0.7436625488344502\n",
      "\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:28<00:00, 18.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 19.669263324512393\n",
      "Precision - 0.8230944993950323\n",
      "Recall - 0.7341368716619234\n",
      "F1-score - 0.7702676177690388\n",
      "F0.5-score - 0.799027943529075\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.8353179282073109\n",
      "Recall - 0.6591475154169802\n",
      "F1-score - 0.721926209636962\n",
      "F0.5-score - 0.7784072373958142\n",
      "\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:28<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 17.95474897267907\n",
      "Precision - 0.8317151450187403\n",
      "Recall - 0.7520122970700416\n",
      "F1-score - 0.7854047572598176\n",
      "F0.5-score - 0.8110460390985672\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.8418237987051596\n",
      "Recall - 0.6785899387887897\n",
      "F1-score - 0.7379092720092764\n",
      "F0.5-score - 0.7905378985608905\n",
      "\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:28<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 16.855773874704266\n",
      "Precision - 0.8444090325187655\n",
      "Recall - 0.7725037820526713\n",
      "F1-score - 0.8033511547685779\n",
      "F0.5-score - 0.8263498400500207\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.8480444593161743\n",
      "Recall - 0.6947769953340359\n",
      "F1-score - 0.7511786706449415\n",
      "F0.5-score - 0.8004642940748162\n",
      "\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:28<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 15.722947502769834\n",
      "Precision - 0.8550182247851792\n",
      "Recall - 0.78720408015894\n",
      "F1-score - 0.8168115496397301\n",
      "F0.5-score - 0.8384135300914743\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.853591996929259\n",
      "Recall - 0.7112664062272344\n",
      "F1-score - 0.7692187643784673\n",
      "F0.5-score - 0.8151913781440484\n",
      "\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:29<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 14.692758808979011\n",
      "Precision - 0.8584387738837393\n",
      "Recall - 0.7975906060894155\n",
      "F1-score - 0.8245632285878337\n",
      "F0.5-score - 0.8438533693109188\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.8489940737420469\n",
      "Recall - 0.7243156845846408\n",
      "F1-score - 0.7744886594075893\n",
      "F0.5-score - 0.8148915804610622\n",
      "\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:29<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 13.887930518469295\n",
      "Precision - 0.8688643893828026\n",
      "Recall - 0.8111303166438659\n",
      "F1-score - 0.8370337584242439\n",
      "F0.5-score - 0.8552607450745344\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.8541094644987943\n",
      "Recall - 0.7405643209359338\n",
      "F1-score - 0.7868304868280891\n",
      "F0.5-score - 0.8235412864475213\n",
      "\n",
      "\n",
      "Training strategy_c model\n",
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:29<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 73.01093282898516\n",
      "Precision - 0.4003498029650982\n",
      "Recall - 0.16529801823431034\n",
      "F1-score - 0.27217713584438724\n",
      "F0.5-score - 0.3218076099451993\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.6999009608703647\n",
      "Recall - 0.2804065458151064\n",
      "F1-score - 0.5284035286088284\n",
      "F0.5-score - 0.585901789596608\n",
      "\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1591/1591 [01:29<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per epoch - 42.5795610753865\n",
      "Precision - 0.6781819578901798\n",
      "Recall - 0.42067628065525914\n",
      "F1-score - 0.5630118332304334\n",
      "F0.5-score - 0.5991488828000391\n",
      "\n",
      "Validating on dev test: \n",
      "Precision - 0.7253244418433605\n",
      "Recall - 0.4345057376038695\n",
      "F1-score - 0.5927697857048532\n",
      "F0.5-score - 0.6459546790072759\n",
      "\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 144/1591 [00:08<01:22, 17.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m metric_handler \u001b[38;5;241m=\u001b[39m MetricsHandler(labels)\n\u001b[1;32m      9\u001b[0m valid_metric \u001b[38;5;241m=\u001b[39m MetricsHandler(labels)\n\u001b[0;32m---> 11\u001b[0m model, train, valid, losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#batch size \u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mwords_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtags_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmetric_handler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalid_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m plotting_data[name] \u001b[38;5;241m=\u001b[39m (train\u001b[38;5;241m.\u001b[39mget_metrics(), losses, valid\u001b[38;5;241m.\u001b[39mget_metrics())\n",
      "File \u001b[0;32m~/Github/pytorch_ner/scripts/training_model.py:44\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, loss_function, data_dict, batch_size, word_indexer, tag_indexer, training_metrics, validation_metrics, num_epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m tag_scores \u001b[38;5;241m=\u001b[39m model(sentence_in)\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(tag_scores, targets)\n\u001b[0;32m---> 44\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     47\u001b[0m prediction \u001b[38;5;241m=\u001b[39m get_tag_indices_from_scores(tag_scores\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/pytorch-nightly/lib/python3.11/site-packages/torch/_tensor.py:503\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    495\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    496\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    501\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    502\u001b[0m     )\n\u001b[0;32m--> 503\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/pytorch-nightly/lib/python3.11/site-packages/torch/autograd/__init__.py:254\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} model\")\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    \n",
    "    metric_handler = MetricsHandler(labels)\n",
    "    valid_metric = MetricsHandler(labels)\n",
    "    \n",
    "    model, train, valid, losses = train_model(model, optimizer,\n",
    "                                  loss_function,\n",
    "                                  data_dict, \n",
    "                                  128, #batch size \n",
    "                                  words_indexer, \n",
    "                                  tags_indexer, \n",
    "                                  metric_handler, \n",
    "                                  valid_metric,\n",
    "                                  num_epochs=10)\n",
    "    \n",
    "    plotting_data[name] = (train.get_metrics(), losses, valid.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, plot_data in plotting_data.items():\n",
    "    train, losses, valid = plot_data\n",
    "    build_training_visualization(name, train, losses, valid, f'visualizations/{name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models\n",
    "for name, model in models.items():\n",
    "    torch.save(model.state_dict(), f'saved_models/{name}.pt')\n",
    "    trained_models[name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strategy_b results on test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xy/Github/pytorch_ner/scripts/metrics.py:5: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return x[1, 1]/(x[1, 1] + x[0, 1])\n",
      "/Users/xy/Github/pytorch_ner/scripts/metrics.py:9: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return x[1, 1] / (x[1, 0] + x[1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - 0.5760847949651751\n",
      "Recall - 0.13429124392375907\n",
      "F1-score - 0.3087931440395692\n",
      "F0.5-score - 0.34340604829976557\n",
      "\n",
      "strategy_c results on test set:\n",
      "Precision - 0.1661809134631242\n",
      "Recall - 0.10629109231351373\n",
      "F1-score - 0.023897488028865127\n",
      "F0.5-score - 0.020430536329697522\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xy/Github/pytorch_ner/scripts/metrics.py:15: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return ((1 + beta**2)*precision*recall)/(beta**2 * precision + recall)\n"
     ]
    }
   ],
   "source": [
    "##Printing test set results\n",
    "##TODO: Extract to scripts and merge with validate method\n",
    "\n",
    "test_metrics = MetricsHandler(labels)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"{name} results on test set:\")\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(words_indexer.elements_to_indices(test_words), dtype=torch.long)\n",
    "        true_vals = tags_indexer.elements_to_indices(test_tags)\n",
    "        tag_scores = model(inputs)\n",
    "        prediction = get_tag_indices_from_scores(tag_scores)\n",
    "        test_metrics.update(prediction, true_vals)\n",
    "        test_metrics.collect()\n",
    "        for metric in test_metrics.metrics_dict.keys():\n",
    "            print(f\"{metric} - {test_metrics.metrics_dict[metric][-1]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
